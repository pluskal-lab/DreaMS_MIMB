{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:17:26.371973Z",
     "start_time": "2025-06-30T16:17:22.682771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# your package\n",
    "from benchmark.utils import annotate_mgf_with_label\n",
    "from benchmark.data.datasets import ChlorineDetectionDataset\n",
    "from benchmark.data.data_module import BenchmarkDataModule\n",
    "from benchmark.models.classifier import MLPClassifier\n",
    "from benchmark.models.lit_module import LitClassifier\n",
    "\n",
    "# transforms\n",
    "from massspecgym.data.transforms import SpecBinner"
   ],
   "id": "9ec5a7004bc60a16",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/lightning_fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:17:26.376684Z",
     "start_time": "2025-06-30T16:17:26.374734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# where your data lives\n",
    "DATA_DIR = Path(\"../data/massspecgym\")\n",
    "ORIG_MGF = DATA_DIR / \"MassSpecGym.mgf\"\n",
    "LABELED_MGF = DATA_DIR / \"MassSpecGym_chlorine.mgf\""
   ],
   "id": "7ea423a6a4e3f568",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T15:13:44.552363Z",
     "start_time": "2025-06-28T15:12:34.505855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define label: check 'FORMULA' metadata\n",
    "label_fn = lambda md: \"Cl\" in md.get(\"formula\", \"\")\n",
    "\n",
    "# write out a new MGF with LABEL=<0.0|1.0> lines\n",
    "annotate_mgf_with_label(ORIG_MGF, LABELED_MGF, label_fn)\n",
    "print(\"Wrote:\", LABELED_MGF.exists())"
   ],
   "id": "710510d1cf21c5d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: True\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:37:18.168383Z",
     "start_time": "2025-06-30T15:36:42.016653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple binning transform: 1 Da bins up to 1000\n",
    "spec_transform = SpecBinner(max_mz=1000.0, bin_width=1.0)\n",
    "\n",
    "ds = ChlorineDetectionDataset(\n",
    "    pth=LABELED_MGF,\n",
    "    spec_transform=spec_transform,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "print(\"Total spectra:\", len(ds))\n",
    "print(ds.metadata['label'].value_counts())\n",
    "\n",
    "dm = BenchmarkDataModule(\n",
    "    dataset=ds,\n",
    "    batch_size=16,\n",
    "    num_workers=0\n",
    ")\n",
    "dm.setup()  # splits into train/val/test"
   ],
   "id": "a917b55fee0a7261",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spectra: 231104\n",
      "label\n",
      "0.0    210799\n",
      "1.0     20305\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.358093Z",
     "start_time": "2025-06-28T16:35:13.340532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grab one training batch to inspect types & shapes\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(\"spec type:\",  type(batch[\"spec\"]))\n",
    "print(\"spec shape: \", batch[\"spec\"].shape)\n",
    "print(\"label type:\", type(batch[\"label\"]))\n",
    "print(\"label shape:\", batch[\"label\"].shape)"
   ],
   "id": "aafa3fabd2d4c6fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec type: <class 'torch.Tensor'>\n",
      "spec shape:  torch.Size([16, 1000])\n",
      "label type: <class 'torch.Tensor'>\n",
      "label shape: torch.Size([16])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.371298Z",
     "start_time": "2025-06-28T16:35:13.366777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. MLP\n",
    "input_dim = int(spec_transform.max_mz / spec_transform.bin_width)\n",
    "mlp = MLPClassifier(input_dim=input_dim, hidden_dims=(32,), dropout=0.1)\n",
    "\n",
    "# 2. Lightning wrapper\n",
    "lit = LitClassifier(mlp, lr=1e-3)"
   ],
   "id": "2a88dd9dbf502bf0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.917296Z",
     "start_time": "2025-06-28T16:35:13.379297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=3,\n",
    "#     accelerator=\"cpu\",  # or \"gpu\", devices=1\n",
    "#     log_every_n_steps=10,\n",
    "# )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    limit_train_batches=5,     # run only 5 training batches\n",
    "    limit_val_batches=3,       # run only 3 validation batches\n",
    "    limit_test_batches=3,      # run only 3 test batches\n",
    "    accelerator=\"cpu\",         # or \"gpu\"\n",
    "    devices=1,\n",
    ")\n",
    "# fit\n",
    "trainer.fit(lit, datamodule=dm)\n",
    "\n",
    "# final test\n",
    "trainer.test(lit, datamodule=dm)"
   ],
   "id": "cc9388fdf6912599",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | model     | MLPClassifier  | 32.1 K\n",
      "1 | train_acc | BinaryAccuracy | 0     \n",
      "2 | val_acc   | BinaryAccuracy | 0     \n",
      "3 | val_auc   | BinaryAUROC    | 0     \n",
      "---------------------------------------------\n",
      "32.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.1 K    Total params\n",
      "0.128     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71e88028a705422b91d95bfbe42e1453"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a3a86ad5f29473e98617666392864d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a4bcfd075da45ccb338641ad1f8accc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1bb137bb2c04feeb7ff2a2c175980a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.0\n",
      "        test_loss           0.7641429901123047\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.7641429901123047, 'test_acc': 0.0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.939001Z",
     "start_time": "2025-06-28T16:35:13.924650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# grab one batch from test loader\n",
    "batch = next(iter(dm.test_dataloader()))\n",
    "specs, labels = batch[\"spec\"], batch[\"label\"]\n",
    "logits = lit(specs)\n",
    "preds = torch.sigmoid(logits)\n",
    "print(\"True:\", labels[:8].tolist())\n",
    "print(\"Pred:\", preds[:8].detach().round().tolist())"
   ],
   "id": "5af14646a83fbfd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Pred: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:42:29.607238Z",
     "start_time": "2025-06-30T15:42:29.593812Z"
    }
   },
   "cell_type": "code",
   "source": "batch = next(iter(dm.test_dataloader()))",
   "id": "90dcd90a22dfe69d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:42:30.622413Z",
     "start_time": "2025-06-30T15:42:30.618340Z"
    }
   },
   "cell_type": "code",
   "source": "batch",
   "id": "2c5a438018d134e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spec': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'label': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'identifier': ['MassSpecGymID0000201',\n",
       "  'MassSpecGymID0000202',\n",
       "  'MassSpecGymID0000203',\n",
       "  'MassSpecGymID0000204',\n",
       "  'MassSpecGymID0000205',\n",
       "  'MassSpecGymID0000206',\n",
       "  'MassSpecGymID0000207',\n",
       "  'MassSpecGymID0000208',\n",
       "  'MassSpecGymID0000209',\n",
       "  'MassSpecGymID0000210',\n",
       "  'MassSpecGymID0000211',\n",
       "  'MassSpecGymID0000212',\n",
       "  'MassSpecGymID0000213',\n",
       "  'MassSpecGymID0000214',\n",
       "  'MassSpecGymID0000215',\n",
       "  'MassSpecGymID0000216']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DreaMS model",
   "id": "e9e5cddc8cda3412"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:17:36.251911Z",
     "start_time": "2025-06-30T16:17:33.186072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from benchmark.models.lit_dreams_module import LitDreamsClassifier\n",
    "from benchmark.data.data_module import BenchmarkDataModule\n",
    "from massspecgym.data.transforms import SpecTokenizer\n",
    "import pytorch_lightning as pl"
   ],
   "id": "86cb3c8138a59335",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:17:48.476153Z",
     "start_time": "2025-06-30T16:17:46.830021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Instantiate your Lightning module, pointing at the fine-tuned checkpoint you care about:\n",
    "lit = LitDreamsClassifier(\n",
    "    ckpt_path=\"/Users/macbook/CODE/DreaMS_MIMB/data/model_checkpoints/ssl_model.ckpt\",\n",
    "    n_highest_peaks=60,\n",
    "    lr=1e-4,\n",
    "    dropout=0.1,\n",
    "    train_encoder=True  # if you want to fine-tune the whole encoder\n",
    ")\n"
   ],
   "id": "da16c5e286dbb539",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:18:23.497600Z",
     "start_time": "2025-06-30T16:17:48.482932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pick N peaks (e.g. 60), yields shape [batch, 61, 2] (including precursor)\n",
    "spec_transform = SpecTokenizer(n_peaks=60)\n",
    "\n",
    "ds = ChlorineDetectionDataset(\n",
    "    pth=LABELED_MGF,\n",
    "    spec_transform=spec_transform,\n",
    "    dtype=torch.float32\n",
    ")"
   ],
   "id": "1365d66b065ef9a8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:18:23.623293Z",
     "start_time": "2025-06-30T16:18:23.503157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2) Prepare your BenchmarkDataModule as before\n",
    "dm = BenchmarkDataModule(dataset=ds, batch_size=16, num_workers=0)\n",
    "dm.setup()"
   ],
   "id": "73fd5d9b68b9d3d4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:18:23.638903Z",
     "start_time": "2025-06-30T16:18:23.628531Z"
    }
   },
   "cell_type": "code",
   "source": "batch = next(iter(dm.test_dataloader()))",
   "id": "121e49faf1664576",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:18:23.649880Z",
     "start_time": "2025-06-30T16:18:23.645604Z"
    }
   },
   "cell_type": "code",
   "source": "batch",
   "id": "a311ad49333ee04e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spec': tensor([[[8.0640e+02, 1.1000e+00],\n",
       "          [8.3049e+01, 1.6216e-01],\n",
       "          [1.2304e+02, 4.7047e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[8.0640e+02, 1.1000e+00],\n",
       "          [3.8418e+02, 1.7918e-01],\n",
       "          [5.4526e+02, 5.0050e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[7.8442e+02, 1.1000e+00],\n",
       "          [1.3410e+02, 1.0000e+00],\n",
       "          [2.3415e+02, 7.9079e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[7.8442e+02, 1.1000e+00],\n",
       "          [1.3410e+02, 4.5377e-01],\n",
       "          [2.3415e+02, 9.0367e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[7.8442e+02, 1.1000e+00],\n",
       "          [1.3410e+02, 1.6896e-01],\n",
       "          [2.3415e+02, 4.8908e-02],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[7.8442e+02, 1.1000e+00],\n",
       "          [1.3410e+02, 4.3061e-02],\n",
       "          [2.4413e+02, 1.0000e+00],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]]]),\n",
       " 'label': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'identifier': ['MassSpecGymID0000201',\n",
       "  'MassSpecGymID0000202',\n",
       "  'MassSpecGymID0000203',\n",
       "  'MassSpecGymID0000204',\n",
       "  'MassSpecGymID0000205',\n",
       "  'MassSpecGymID0000206',\n",
       "  'MassSpecGymID0000207',\n",
       "  'MassSpecGymID0000208',\n",
       "  'MassSpecGymID0000209',\n",
       "  'MassSpecGymID0000210',\n",
       "  'MassSpecGymID0000211',\n",
       "  'MassSpecGymID0000212',\n",
       "  'MassSpecGymID0000213',\n",
       "  'MassSpecGymID0000214',\n",
       "  'MassSpecGymID0000215',\n",
       "  'MassSpecGymID0000216']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:18:30.373444Z",
     "start_time": "2025-06-30T16:18:30.329135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3) Trainer configuration\n",
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=5,\n",
    "#     accelerator=\"gpu\",    # or \"mps\"\n",
    "#     devices=1,\n",
    "#     num_sanity_val_steps=0,\n",
    "# )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    limit_train_batches=5,     # run only 5 training batches\n",
    "    limit_val_batches=3,       # run only 3 validation batches\n",
    "    limit_test_batches=3,      # run only 3 test batches\n",
    "    accelerator=\"cpu\",         # or \"gpu\"\n",
    "    devices=1,\n",
    ")"
   ],
   "id": "60726693fddacdde",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:18:37.596915Z",
     "start_time": "2025-06-30T16:18:31.204450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4) Train\n",
    "trainer.fit(lit, datamodule=dm)"
   ],
   "id": "39a8783e3b4f11cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | DreamsClassifier | 95.6 M\n",
      "1 | train_acc | BinaryAccuracy   | 0     \n",
      "2 | val_acc   | BinaryAccuracy   | 0     \n",
      "3 | val_auc   | BinaryAUROC      | 0     \n",
      "-----------------------------------------------\n",
      "95.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "95.6 M    Total params\n",
      "382.202   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b100ec4a4224915aae317c2d5e493b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad947b4dbe6c46ccae8c7f4955c4ae5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "504f544950d5452ca881daa38b78f102"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:19:06.968814Z",
     "start_time": "2025-06-30T16:19:06.017403Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.test(lit, datamodule=dm)",
   "id": "ec300858170b3781",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85bf3e22ce86456a989fdff7cb7697f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    1.0\n",
      "        test_loss           0.15856797993183136\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.15856797993183136, 'test_acc': 1.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:21:09.329291Z",
     "start_time": "2025-06-30T16:21:08.617173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5) Save checkpoint of your fine-tuned model\n",
    "trainer.save_checkpoint(\"dreams_chlorine_finetuned.ckpt\")"
   ],
   "id": "2c61a49f0dbec47f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load predtrained DreaMS",
   "id": "e89f1a7f92574f24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:27:24.448170Z",
     "start_time": "2025-06-30T16:27:22.358580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Reload your tuned model (you already did this):\n",
    "lit2 = LitDreamsClassifier.load_from_checkpoint(\"dreams_chlorine_finetuned.ckpt\")\n",
    "lit2.eval()"
   ],
   "id": "94e4d3dc939c18af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitDreamsClassifier(\n",
       "  (model): DreamsClassifier(\n",
       "    (spec_encoder): DreaMS(\n",
       "      (fourier_enc): FourierFeatures()\n",
       "      (ff_fourier): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=11994, out_features=512, bias=True)\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "          (5): ReLU()\n",
       "          (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (7): Dropout(p=0.1, inplace=False)\n",
       "          (8): ReLU()\n",
       "          (9): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (10): Dropout(p=0.1, inplace=False)\n",
       "          (11): ReLU()\n",
       "          (12): Linear(in_features=512, out_features=980, bias=True)\n",
       "          (13): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (ff_peak): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=44, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (transformer_encoder): TransformerEncoder(\n",
       "        (atts): ModuleList(\n",
       "          (0-6): 7 x MultiheadAttention()\n",
       "        )\n",
       "        (ffs): ModuleList(\n",
       "          (0-6): 7 x FeedForward(\n",
       "            (in_proj): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "            (out_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (scales): ModuleList(\n",
       "          (0-14): 15 x LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin_out): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       "  (train_acc): BinaryAccuracy()\n",
       "  (val_acc): BinaryAccuracy()\n",
       "  (val_auc): BinaryAUROC()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:27:33.170793Z",
     "start_time": "2025-06-30T16:27:33.149846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2) (Re)create a Trainer for testing:\n",
    "test_trainer = pl.Trainer(accelerator=\"cpu\", devices=1)"
   ],
   "id": "82ca8871483a5d72",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:32:16.902285Z",
     "start_time": "2025-06-30T16:27:43.488164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3) Run on your existing BenchmarkDataModule:\n",
    "test_results = test_trainer.test(lit2, datamodule=dm)"
   ],
   "id": "ec1a9c425dfc06a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d34fd90814a840c4b3f1a728cd31ae64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8043404221534729\n",
      "        test_loss           0.42470064759254456\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T16:32:16.964525Z",
     "start_time": "2025-06-30T16:32:16.961804Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_results)",
   "id": "17b24558f9bd1aff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': 0.42470064759254456, 'test_acc': 0.8043404221534729}]\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
