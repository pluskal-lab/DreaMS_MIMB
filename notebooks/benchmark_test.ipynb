{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:34:30.717781Z",
     "start_time": "2025-06-28T16:34:26.337120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# your package\n",
    "from benchmark.utils import annotate_mgf_with_label\n",
    "from benchmark.data.datasets import ChlorineDetectionDataset\n",
    "from benchmark.data.data_module import BenchmarkDataModule\n",
    "from benchmark.models.classifier import MLPClassifier\n",
    "from benchmark.models.lit_module import LitClassifier\n",
    "\n",
    "# transforms\n",
    "from massspecgym.data.transforms import SpecBinner"
   ],
   "id": "9ec5a7004bc60a16",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/lightning_fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:34:30.722570Z",
     "start_time": "2025-06-28T16:34:30.720517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# where your data lives\n",
    "DATA_DIR = Path(\"../data/massspecgym\")\n",
    "ORIG_MGF = DATA_DIR / \"MassSpecGym.mgf\"\n",
    "LABELED_MGF = DATA_DIR / \"MassSpecGym_chlorine.mgf\""
   ],
   "id": "7ea423a6a4e3f568",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T15:13:44.552363Z",
     "start_time": "2025-06-28T15:12:34.505855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define label: check 'FORMULA' metadata\n",
    "label_fn = lambda md: \"Cl\" in md.get(\"formula\", \"\")\n",
    "\n",
    "# write out a new MGF with LABEL=<0.0|1.0> lines\n",
    "annotate_mgf_with_label(ORIG_MGF, LABELED_MGF, label_fn)\n",
    "print(\"Wrote:\", LABELED_MGF.exists())"
   ],
   "id": "710510d1cf21c5d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: True\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.334969Z",
     "start_time": "2025-06-28T16:34:30.895894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# simple binning transform: 1 Da bins up to 1000\n",
    "spec_transform = SpecBinner(max_mz=1000.0, bin_width=1.0)\n",
    "\n",
    "ds = ChlorineDetectionDataset(\n",
    "    pth=LABELED_MGF,\n",
    "    spec_transform=spec_transform,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "print(\"Total spectra:\", len(ds))\n",
    "print(ds.metadata['label'].value_counts())\n",
    "\n",
    "dm = BenchmarkDataModule(\n",
    "    dataset=ds,\n",
    "    batch_size=16,\n",
    "    num_workers=0\n",
    ")\n",
    "dm.setup()  # splits into train/val/test"
   ],
   "id": "a917b55fee0a7261",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spectra: 231104\n",
      "label\n",
      "0.0    210799\n",
      "1.0     20305\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.358093Z",
     "start_time": "2025-06-28T16:35:13.340532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grab one training batch to inspect types & shapes\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(\"spec type:\",  type(batch[\"spec\"]))\n",
    "print(\"spec shape: \", batch[\"spec\"].shape)\n",
    "print(\"label type:\", type(batch[\"label\"]))\n",
    "print(\"label shape:\", batch[\"label\"].shape)"
   ],
   "id": "aafa3fabd2d4c6fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec type: <class 'torch.Tensor'>\n",
      "spec shape:  torch.Size([16, 1000])\n",
      "label type: <class 'torch.Tensor'>\n",
      "label shape: torch.Size([16])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.371298Z",
     "start_time": "2025-06-28T16:35:13.366777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. MLP\n",
    "input_dim = int(spec_transform.max_mz / spec_transform.bin_width)\n",
    "mlp = MLPClassifier(input_dim=input_dim, hidden_dims=(32,), dropout=0.1)\n",
    "\n",
    "# 2. Lightning wrapper\n",
    "lit = LitClassifier(mlp, lr=1e-3)"
   ],
   "id": "2a88dd9dbf502bf0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.917296Z",
     "start_time": "2025-06-28T16:35:13.379297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=3,\n",
    "#     accelerator=\"cpu\",  # or \"gpu\", devices=1\n",
    "#     log_every_n_steps=10,\n",
    "# )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    limit_train_batches=5,     # run only 5 training batches\n",
    "    limit_val_batches=3,       # run only 3 validation batches\n",
    "    limit_test_batches=3,      # run only 3 test batches\n",
    "    accelerator=\"cpu\",         # or \"gpu\"\n",
    "    devices=1,\n",
    ")\n",
    "# fit\n",
    "trainer.fit(lit, datamodule=dm)\n",
    "\n",
    "# final test\n",
    "trainer.test(lit, datamodule=dm)"
   ],
   "id": "cc9388fdf6912599",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | model     | MLPClassifier  | 32.1 K\n",
      "1 | train_acc | BinaryAccuracy | 0     \n",
      "2 | val_acc   | BinaryAccuracy | 0     \n",
      "3 | val_auc   | BinaryAUROC    | 0     \n",
      "---------------------------------------------\n",
      "32.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.1 K    Total params\n",
      "0.128     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71e88028a705422b91d95bfbe42e1453"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a3a86ad5f29473e98617666392864d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a4bcfd075da45ccb338641ad1f8accc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/Users/macbook/UTILS/anaconda3/envs/dreams_mimb/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1bb137bb2c04feeb7ff2a2c175980a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.0\n",
      "        test_loss           0.7641429901123047\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.7641429901123047, 'test_acc': 0.0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:35:13.939001Z",
     "start_time": "2025-06-28T16:35:13.924650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# grab one batch from test loader\n",
    "batch = next(iter(dm.test_dataloader()))\n",
    "specs, labels = batch[\"spec\"], batch[\"label\"]\n",
    "logits = lit(specs)\n",
    "preds = torch.sigmoid(logits)\n",
    "print(\"True:\", labels[:8].tolist())\n",
    "print(\"Pred:\", preds[:8].detach().round().tolist())"
   ],
   "id": "5af14646a83fbfd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Pred: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da16c5e286dbb539"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
